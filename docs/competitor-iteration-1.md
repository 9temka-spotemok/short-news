## Итерация 1 — Расширенный сбор новостей и базовая аналитика

### Цель
- Углубить обработку новостного контента и подготовить базовую платформу для многофакторной аналитики.

### Основные задачи
- **Инвентаризация источников**: собрать по каждому конкуренту список URL и классифицировать их по типам (`news_feed`, `blog`, `press_release`, `update`).
- **Конфигурация скрапера**: добавить к `universal_scraper` поддержку множественных источников, индивидуальные таймауты, retry-политику, fallback-стратегии для SPA/Cloudflare (headless-браузер, прокси), контроль rate limit.
- **Качество данных**: сохранять сырые снапшоты страниц, устранять дубликаты по URL/хешу, валидировать даты публикаций.
- **NLP-конвейер**: реализовать классификацию тем, оценку тональности и свежести/приоритета; логировать качество моделей и ошибки (failure bucket).
- **Расширение схематических данных**: добавить к новостям поля `topic`, `sentiment`, `priority_score`, `source_type`, ссылку на сырую копию.
- **API**: модифицировать `compareCompanies` и связанные ручки, чтобы отдавать новые метрики и атрибуты.
- **Frontend**: обновить `CompetitorAnalysisPage` (фильтры по типу источника/теме, визуализация тональности, карточки приоритетов).
- **Документация и процессы**: обновить `README` (раздел по источникам и ответственности файлов), задокументировать новые конфиги; подготовить инструкции для команды по работе с расширенным NLP.
- **Тестирование**: покрыть unit-тестами скрапер и NLP-конвейер, интеграционными тестами API, e2e сценариями отображения метрик на фронтенде.

### Критерии готовности
- Все новости сохраняются с расширенным набором атрибутов и ссылкой на сырой снапшот.
- UI корректно отображает новые метрики без регрессий в существующих потоках.
- Скрапер устойчиво обходит защищённые (SPA/Cloudflare) источники или фиксирует fallback.
- Набор автотестов включает проверку новых атрибутов и визуальных элементов.
- Обновлённый `README` отражает ответственность новых модулей и конфигураций.

